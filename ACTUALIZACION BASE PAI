import pandas as pd
import customtkinter as ctk
from tkinter import filedialog, messagebox
import threading
import os
from PIL import Image


# --- Requisitos previos ---
# pip install openpyxl
# pip install XlsxWriter
# pip install customtkinter
# pip install Pillow

class AppPAIUpdater:
    def __init__(self, root):
        self.root = root
        self.root.title("Moderno Actualizador de Base PAI (v. Final)")
        self.root.geometry("600x620")
        self.root.resizable(False, False)

        ctk.set_appearance_mode("System")
        ctk.set_default_color_theme("blue")

        self.icon_file = self.load_icon("icons/file.png")
        self.icon_folder = self.load_icon("icons/folder.png")
        self.icon_play = self.load_icon("icons/play.png")

        self.pai_path = ctk.StringVar()
        self.bdua_path = ctk.StringVar()
        self.ftp_path = ctk.StringVar()
        self.output_dir = ctk.StringVar()
        self.output_filename = ctk.StringVar(value="BASE_PAI_ACTUALIZADA")
        self.generate_report = ctk.BooleanVar(value=True)
        self.export_txt = ctk.BooleanVar(value=True)
        self.export_excel = ctk.BooleanVar(value=True)

        main_frame = ctk.CTkFrame(self.root, fg_color="transparent")
        main_frame.pack(expand=True, fill="both", padx=20, pady=20)

        title_label = ctk.CTkLabel(main_frame, text="Actualizador de Base PAI",
                                   font=ctk.CTkFont(size=20, weight="bold"))
        title_label.pack(pady=(0, 25))

        self.create_file_selector(main_frame, "1. Base PAI (Estructura):", self.pai_path, self.icon_file)
        self.create_file_selector(main_frame, "2. BDUA (Pacientes):", self.bdua_path, self.icon_file)
        self.create_file_selector(main_frame, "3. FTP (Biológicos):", self.ftp_path, self.icon_file)

        self.create_directory_selector(main_frame, "4. Carpeta de Salida:", self.output_dir, self.icon_folder)
        self.create_text_entry(main_frame, "5. Nombre de Archivos:", self.output_filename)

        export_frame = ctk.CTkFrame(main_frame)
        export_frame.pack(pady=15, padx=10, fill="x")

        export_label = ctk.CTkLabel(export_frame, text="Formatos de Salida:", font=ctk.CTkFont(weight="bold"))
        export_label.pack(pady=(5, 10))

        txt_check = ctk.CTkCheckBox(export_frame, text="Exportar a TXT (delimitado por tabulaciones)",
                                    variable=self.export_txt)
        txt_check.pack(anchor="w", padx=20, pady=5)

        excel_check = ctk.CTkCheckBox(export_frame, text="Exportar a Excel (.xlsx)", variable=self.export_excel)
        excel_check.pack(anchor="w", padx=20, pady=(5, 10))

        report_check = ctk.CTkCheckBox(main_frame, text="Generar reporte de cambios detallado (recomendado)",
                                       variable=self.generate_report)
        report_check.pack(pady=10, anchor="w")

        process_button = ctk.CTkButton(main_frame, text="Generar Archivos", command=self.start_processing,
                                       height=40, font=ctk.CTkFont(size=14, weight="bold"), image=self.icon_play)
        process_button.pack(pady=10, fill="x")

        self.progress = ctk.CTkProgressBar(main_frame, orientation="horizontal")
        self.progress.set(0)
        self.progress.pack(pady=10, fill="x")

        self.status_label = ctk.CTkLabel(main_frame, text="Listo para iniciar. ✨", anchor="center")
        self.status_label.pack(pady=(10, 0), fill="x")

    def universal_date_parser(self, date_val):
        if pd.isna(date_val) or str(date_val).strip() == '':
            return pd.NaT

        date_str = str(date_val).strip()

        formats_to_try = [
            '%Y-%m-%d',
            '%Y/%m/%d',
            '%d/%m/%Y',
            '%d-%m-%Y',
        ]

        for fmt in formats_to_try:
            try:
                return pd.to_datetime(date_str, format=fmt)
            except (ValueError, TypeError):
                continue

        try:
            return pd.to_datetime(date_str, dayfirst=True)
        except (ValueError, TypeError):
            return pd.NaT

    def load_icon(self, path, size=(20, 20)):
        try:
            return ctk.CTkImage(Image.open(path), size=size)
        except FileNotFoundError:
            print(f"Advertencia: No se encontró el ícono en la ruta: {path}")
            return None

    def create_file_selector(self, parent, label_text, var, icon):
        frame = ctk.CTkFrame(parent, fg_color="transparent")
        frame.pack(fill="x", pady=5)
        label = ctk.CTkLabel(frame, text=label_text, width=180, anchor="w")
        label.pack(side="left")
        entry = ctk.CTkEntry(frame, textvariable=var, state="disabled")
        entry.pack(side="left", expand=True, fill="x", padx=10)
        button = ctk.CTkButton(frame, text="", image=icon, width=32,
                               command=lambda: self.browse_file(var, "Seleccionar archivo"))
        button.pack(side="right")

    def create_directory_selector(self, parent, label_text, var, icon):
        frame = ctk.CTkFrame(parent, fg_color="transparent")
        frame.pack(fill="x", pady=5)
        label = ctk.CTkLabel(frame, text=label_text, width=180, anchor="w")
        label.pack(side="left")
        entry = ctk.CTkEntry(frame, textvariable=var, state="disabled")
        entry.pack(side="left", expand=True, fill="x", padx=10)
        button = ctk.CTkButton(frame, text="", image=icon, width=32,
                               command=lambda: self.browse_directory(var, "Seleccionar carpeta de destino"))
        button.pack(side="right")

    def create_text_entry(self, parent, label_text, var):
        frame = ctk.CTkFrame(parent, fg_color="transparent")
        frame.pack(fill="x", pady=5)
        label = ctk.CTkLabel(frame, text=label_text, width=180, anchor="w")
        label.pack(side="left")
        entry = ctk.CTkEntry(frame, textvariable=var)
        entry.pack(side="left", expand=True, fill="x", padx=10)

    def browse_file(self, var, title):
        filename = filedialog.askopenfilename(title=title, filetypes=[("Archivos de Texto y CSV", "*.txt *.csv"),
                                                                      ("Todos los archivos", "*.*")])
        if filename:
            var.set(os.path.basename(filename))
            setattr(self, f"full_path_{id(var)}", filename)

    def browse_directory(self, var, title):
        directory = filedialog.askdirectory(title=title)
        if directory:
            var.set(directory)

    def get_full_path(self, var):
        return getattr(self, f"full_path_{id(var)}", var.get())

    def start_processing(self):
        if not all([self.pai_path.get(), self.bdua_path.get(), self.ftp_path.get(), self.output_dir.get(),
                    self.output_filename.get()]):
            messagebox.showerror("Error", "Por favor, completa todos los campos de archivos y carpetas.")
            return

        if not self.export_txt.get() and not self.export_excel.get():
            messagebox.showerror("Error de Exportación",
                                 "Debes seleccionar al menos un formato de salida (TXT o Excel).")
            return

        thread = threading.Thread(target=self.process_files)
        thread.start()

    def process_files(self):
        try:
            self.cambios_log = []
            self.status_label.configure(text="Iniciando proceso...")
            self.progress.set(0)

            def standardize_column(df, potential_names, target_name, file_type):
                df_renamed = df.copy()
                for name in potential_names:
                    if name in df_renamed.columns:
                        df_renamed.rename(columns={name: target_name}, inplace=True)
                        return df_renamed
                raise ValueError(
                    f"Error en el archivo {file_type}:\n\nNo se encontró la columna para '{target_name}'. Se buscaron los nombres: {potential_names}.\n\nPor favor, revisa el archivo.")

            mapa_columnas_bdua = {'Serial_BDUA': 'COD_BDUA', 'Codigo_Entidad': 'REGIMEN',
                                  'Primerapellido_afiliado': 'APE1', 'Segundoapellido_afiliado': 'APE2',
                                  'Primernombre_afiliado': 'NOM1', 'Segundonombre_afiliado': 'NOM2',
                                  'Fec_Nac_Afiliado': 'FEC_NAC', 'Sexo_afiliado': 'GENERO',
                                  'Departamento': 'DEPARTAMENTO', 'Municipio': 'MUNICIPIO', 'Zona': 'ZONA',
                                  'Fecha_Afiliación': 'FEC_AFILIACION', 'Estado_Afiliacion': 'ESTADO',
                                  'NombreRazonSocial': 'IPS_PRIMARIA', 'Direccion_Residencia': 'Direccón',
                                  'Telefonocel1': 'teléfono', 'Curso de Vida': 'CICLO_VIDA', 'Edad en años': 'AÑOS',
                                  'Edad en meses': 'MESES'}
            equivalencias_bio = {"BCG": ["BCG UNICA"],
                                 "ANTI HB": ["HB PEDIATRICA PRIMERA", "HB PEDIATRICA SEGUNDA", "HB PEDIATRICA TERCERA",
                                             "HB PEDIATRICA REFUERZO"],
                                 "PENTAVALENTE 1 DOSIS": ["PENTAVALENTE (DPTa-Hib-HB) PRIMERA"],
                                 "POLIO 1 DOSIS": ["POLIO INACTIVADO (VIP) PRIMERA", "POLIO ORAL (VOP) PRIMERA"],
                                 "NEUMOCOCO 1 DOSIS": ["NEUMOCOCO CONJUGADO 10 VALENTE PRIMERA",
                                                       "NEUMOCOCO CONJUGADO 13 VALENTE PRIMERA"],
                                 "ROTAVIRUS 1 DOSIS": ["ROTAVIRUS PRIMERA"],
                                 "PENTAVALENTE 2 DOSIS": ["PENTAVALENTE (DPTa-Hib-HB) SEGUNDA"],
                                 "POLIO 2 DOSIS": ["POLIO INACTIVADO (VIP) SEGUNDA", "POLIO ORAL (VOP) SEGUNDA"],
                                 "NEUMOCOCO 2 DOSIS": ["NEUMOCOCO CONJUGADO 10 VALENTE SEGUNDA",
                                                       "NEUMOCOCO CONJUGADO 13 VALENTE SEGUNDA"],
                                 "ROTAVIRUS 2 DOSIS": ["ROTAVIRUS SEGUNDA"],
                                 "PENTAVALENTE 3 DOSIS": ["PENTAVALENTE (DPTa-Hib-HB) TERCERA"],
                                 "POLIO 3 DOSIS": ["POLIO INACTIVADO (VIP) TERCERA", "POLIO ORAL (VOP) TERCERA"],
                                 "Influenza 6 a 23 1 DOSIS": ["INFLUENZA PEDIATRICA PRIMERA"],
                                 "Influenza 6 a 23 2 DOSIS": ["INFLUENZA PEDIATRICA SEGUNDA"],
                                 "Influenza 6 a 23 REFUERZO": [
                                     "INFLUENZA PEDIATRICA TERCERA",  # A veces la tercera dosis funciona como refuerzo
                                     "INFLUENZA PEDIATRICA REFUERZO"
                                 ],
                                 "TRIPLE VIRAL 1 DOSIS": ["TRIPLE VIRAL PRIMERA"],
                                 "NEUMOCOCO 3 DOSIS": ["NEUMOCOCO CONJUGADO 10 VALENTE REFUERZO",
                                                       "NEUMOCOCO CONJUGADO 13 VALENTE TERCERA",
                                                       "NEUMOCOCO CONJUGADO 13 VALENTE REFUERZO"],
                                 "HEPATITIS A": ["HA PEDIATRICA UNICA"], "VARICELA 1 DOSIS": ["VARICELA PRIMERA"],
                                 "DTP 1 REF": ["D.P.T PRIMER REFUERZO", "PENTAVALENTE (DPTa-Hib-HB) PRIMER REFUERZO"],
                                 "POLIO 1 REF": ["POLIO INACTIVADO (VIP) PRIMER REFUERZO",
                                                 "POLIO ORAL (VOP) PRIMER REFUERZO"], "FIEBRE AMARILLA": ["FA UNICA"],
                                 "TRIPLE VIRAL  REF": ["TRIPLE VIRAL REFUERZO"],
                                 "POLIO 2 REF": ["POLIO INACTIVADO (VIP) SEGUNDO REFUERZO",
                                                 "POLIO ORAL (VOP) SEGUNDO REFUERZO"],
                                 "DPT 2 REF": ["PENTAVALENTE (DPTa-Hib-HB) SEGUNDO REFUERZO", "D.P.T SEGUNDO REFUERZO"],
                                 "VARICELA REF": ["VARICELA REFUERZO"],
                                 "SARAMPION RUBEOLA ADICIONAL": ["SARAMPION RUBEOLA ADICIONAL"],
                                 "VPH PRIMERA DOSIS INICIAL": ["VPH PRIMERA"],
                                 "VPH SEGUNDA DESPUES DE 6 MESES": ["VPH SEGUNDA"],
                                 "TD1: DOSIS INICIAL": ["TD ADULTOS PRIMERA"],
                                 "TD2: AL MES DE TD1": ["TD ADULTOS SEGUNDA"],
                                 "TD3: a los 6 medes de TD3 ": ["TD ADULTOS TERCERA"],
                                 "TD4:  al año  de TD3": ["TD ADULTOS CUARTA"],
                                 "TD5: al año de TD4": ["TD ADULTOS QUINTA"],
                                 "REF cada 10 años ": ["TD ADULTOS PRIMER REFUERZO"],
                                 "INFLUENZA ESTACIONAL": ["INFLUENZA ADULTOS ANUAL"],
                                 "Covid 19 1 dosis": ["COVID SINOVAC PRIMERA", "COVID PFIZER PRIMERA",
                                                      "COVID MODERNA PRIMERA", "COVID JANSSEN UNICA",
                                                      "COVID ASTRAZENECA PRIMERA"],
                                 "covid 19 2 dosis": ["COVID SINOVAC SEGUNDA", "COVID PFIZER SEGUNDA",
                                                      "COVID MODERNA SEGUNDA", "COVID JANSSEN SEGUNDA",
                                                      "COVID ASTRAZENECA SEGUNDA"],
                                 "Covid 19 1 Refuerzo": ["COVID SINOVAC REFUERZO", "COVID SINOVAC PRIMER REFUERZO",
                                                         "COVID PFIZER REFUERZO", "COVID PFIZER PRIMER REFUERZO",
                                                         "COVID MODERNA REFUERZO", "COVID MODERNA PRIMER",
                                                         "COVID JANSSEN REFUERZO REFUERZO",
                                                         "COVID JANSSEN PRIMER REFUERZO", "COVID ASTRAZENECA REFUERZO",
                                                         "COVID ASTRAZENECA PRIMER REFUERZO"],
                                 "covid-19 2 Refuerzo": ["COVID SINOVAC SEGUNDO REFUERZO",
                                                         "COVID PFIZER SEGUNDO REFUERZO",
                                                         "COVID MODERNA SEGUNDO REFUERZO",
                                                         "COVID JANSSEN SEGUNDO REFUERZO",
                                                         "COVID ASTRAZENECA SEGUNDO REFUERZO"],
                                 "TDAP": ["TdaP GESTANTE ANUAL"], }

            self.status_label.configure(text="Paso 1/5: Cargando y estandarizando archivos...")
            self.progress.set(0.1)

            pai_full_path = self.get_full_path(self.pai_path)
            bdua_full_path = self.get_full_path(self.bdua_path)
            ftp_full_path = self.get_full_path(self.ftp_path)

            base_pai_df = pd.read_csv(pai_full_path, sep='\t', on_bad_lines='warn', dtype=str, encoding='latin-1')
            bdua_df = pd.read_csv(bdua_full_path, sep='\t', on_bad_lines='warn', dtype=str, encoding='latin-1')
            ftp_df = pd.read_csv(ftp_full_path, sep='\t', on_bad_lines='warn', dtype=str, encoding='latin-1')

            for df in [base_pai_df, bdua_df, ftp_df]: df.columns = df.columns.str.strip()
            pai_original_columns = base_pai_df.columns.tolist()
            base_pai_df = standardize_column(base_pai_df, ['NUMERO DOCUMENTO', 'NUM_DOC', 'Documento'], 'NUM_DOC',
                                             'Base PAI')
            bdua_df = standardize_column(bdua_df, ['Numeroidentificación_afiliado', 'NUM_DOC'], 'NUM_DOC', 'BDUA')
            ftp_df = standardize_column(ftp_df, ['Documento', 'NUM_DOC'], 'NUM_DOC', 'FTP')
            bdua_df = standardize_column(bdua_df, ['Tipodocumento_afiliado', 'TIPO_DOC', 'TIPO'], 'TIPO', 'BDUA')
            ftp_df = standardize_column(ftp_df, ['TipoIdentificacion', 'Tipo Documento', 'TIPO_DOC', 'TIPO'], 'TIPO',
                                        'FTP')
            bdua_df = standardize_column(bdua_df, ['codsiris', 'COD_SIRIS'], 'COD_SIRIS', 'BDUA')
            base_pai_df = standardize_column(base_pai_df, ['codsiris', 'COD_SIRIS'], 'COD_SIRIS', 'Base PAI')
            for df in [base_pai_df, bdua_df, ftp_df]:
                if 'NUM_DOC' in df.columns: df['NUM_DOC'] = df['NUM_DOC'].str.strip()
                if 'TIPO' in df.columns: df['TIPO'] = df['TIPO'].str.strip()
                if 'COD_SIRIS' in df.columns: df['COD_SIRIS'] = df['COD_SIRIS'].str.strip()
            self.progress.set(0.25)
            self.status_label.configure(text="Paso 2/5: Eliminando duplicados y cruzando por COD_SIRIS...")
            bdua_unique_df = bdua_df.drop_duplicates(subset=['COD_SIRIS']).copy()
            base_pai_unique_df = base_pai_df.drop_duplicates(subset=['COD_SIRIS']).copy()
            master_patients = bdua_unique_df[['COD_SIRIS']].copy()
            df_merged = pd.merge(master_patients, bdua_unique_df, on='COD_SIRIS', how='left')
            df_merged = pd.merge(df_merged, base_pai_unique_df, on='COD_SIRIS', how='left', suffixes=('_bdua', '_pai'))
            df_merged['NUM_DOC'] = df_merged['NUM_DOC_bdua'].fillna(df_merged['NUM_DOC_pai'])
            df_merged['TIPO'] = df_merged['TIPO_bdua'].fillna(df_merged['TIPO_pai'])
            df_merged.rename(columns=mapa_columnas_bdua, inplace=True)
            for col in pai_original_columns:
                col_pai = col + '_pai' if col + '_pai' in df_merged.columns else col
                if col in df_merged.columns and col_pai in df_merged.columns and col != col_pai:
                    if self.generate_report.get():
                        cambios_df = df_merged[(df_merged[col].notna()) & (df_merged[col] != df_merged[col_pai])][
                            ['NUM_DOC', col_pai, col]].copy()
                        for _, row in cambios_df.iterrows(): self.cambios_log.append(
                            {'NUM_DOC': row['NUM_DOC'], 'CAMPO_MODIFICADO': col, 'VALOR_ANTERIOR': str(row[col_pai]),
                             'VALOR_NUEVO': str(row[col]), 'FUENTE': 'BDUA'})

                        # --- LÍNEA CORREGIDA PARA ELIMINAR EL FUTUREWARNING ---
                    df_merged[col] = df_merged[col].fillna(df_merged[col_pai])

            base_actualizada = df_merged
            cols_to_drop = [col for col in base_actualizada.columns if col.endswith('_bdua') or col.endswith('_pai')]
            base_actualizada.drop(columns=cols_to_drop, inplace=True)
            self.progress.set(0.4)
            # --- REEMPLAZA LA SECCIÓN DEL PASO 3 CON ESTO ---
            self.status_label.configure(text="Paso 3/5: Actualizando biológicos por Documento y Tipo...")
            total_cols = len(equivalencias_bio)

            for i, (pai_col, ftp_cols) in enumerate(equivalencias_bio.items()):
                if pai_col in pai_original_columns:
                    if pai_col in base_actualizada.columns:
                        base_actualizada[pai_col] = base_actualizada[pai_col].apply(self.universal_date_parser)

                    # 1. Filtramos las columnas que necesitamos del FTP
                    valid_ftp_cols = [c for c in ftp_cols if c in ftp_df.columns]

                    if valid_ftp_cols:
                        ftp_subset = ftp_df[['NUM_DOC', 'TIPO'] + valid_ftp_cols].copy()

                        # 2. Convertimos todas las columnas de fecha del FTP a formato datetime
                        for col in valid_ftp_cols:
                            ftp_subset[col] = ftp_subset[col].apply(self.universal_date_parser)

                        # 3. Calculamos la fecha máxima por FILA en el FTP
                        ftp_subset['max_date_fila'] = ftp_subset[valid_ftp_cols].max(axis=1)

                        # 4. ¡ESTA ES LA CLAVE!: Agrupamos por paciente y nos quedamos con la fecha máxima de todas sus filas
                        ftp_max_per_patient = ftp_subset.groupby(['NUM_DOC', 'TIPO'])[
                            'max_date_fila'].max().reset_index()
                        ftp_max_per_patient.rename(columns={'max_date_fila': 'max_date_ftp'}, inplace=True)

                        # 5. Cruzamos con la base actualizada
                        base_actualizada = pd.merge(base_actualizada, ftp_max_per_patient, on=['NUM_DOC', 'TIPO'],
                                                    how='left')

                        # 6. Lógica de comparación (Reporte)
                        if self.generate_report.get() and pai_col in base_actualizada.columns:
                            mask_cambio = (base_actualizada['max_date_ftp'].notna()) & (
                                    (pd.isna(base_actualizada[pai_col])) | (
                                        base_actualizada['max_date_ftp'] > base_actualizada[pai_col])
                            )
                            cambios_ftp_df = base_actualizada[mask_cambio].copy()

                            for _, row in cambios_ftp_df.iterrows():
                                val_ant = '' if pd.isna(row[pai_col]) else row[pai_col].strftime('%d/%m/%Y')
                                val_nue = row['max_date_ftp'].strftime('%d/%m/%Y')
                                if val_ant != val_nue:
                                    self.cambios_log.append({
                                        'NUM_DOC': row['NUM_DOC'], 'CAMPO_MODIFICADO': pai_col,
                                        'VALOR_ANTERIOR': val_ant, 'VALOR_NUEVO': val_nue, 'FUENTE': 'FTP'
                                    })

                        # 7. Actualizamos la columna con el valor más reciente
                        if pai_col in base_actualizada.columns:
                            base_actualizada[pai_col] = base_actualizada[[pai_col, 'max_date_ftp']].max(axis=1)
                        else:
                            base_actualizada[pai_col] = base_actualizada['max_date_ftp']

                        base_actualizada.drop(columns=['max_date_ftp'], inplace=True)

                self.progress.set(0.4 + (((i + 1) / total_cols) * 0.5))
            self.status_label.configure(text="Paso 4/5: Reconstruyendo estructura final...")
            columnas_finales = [col for col in pai_original_columns if col in base_actualizada.columns]
            final_df = base_actualizada[columnas_finales].copy()
            for col in final_df.select_dtypes(include=['datetime64[ns]']).columns: final_df[col] = final_df[
                col].dt.strftime('%d/%m/%Y')
            final_df.fillna('', inplace=True)
            valores_a_eliminar = ['0/01/1900', '#N/D', '00/01/1900']
            final_df.replace(valores_a_eliminar, '', inplace=True)
            final_df = final_df.loc[:, ~final_df.columns.duplicated(keep='first')]
            self.status_label.configure(text="Paso 5/5: Guardando archivos...")
            self.progress.set(0.95)
            output_dir = self.output_dir.get()
            base_filename = self.output_filename.get()

            info_message_parts = []
            if self.export_txt.get():
                txt_path = os.path.join(output_dir, f"{base_filename}.txt")
                final_df.to_csv(txt_path, index=False, sep='\t')
                info_message_parts.append(f"- {txt_path}")

            if self.export_excel.get():
                xlsx_path = os.path.join(output_dir, f"{base_filename}.xlsx")
                final_df.to_excel(xlsx_path, index=False, engine='xlsxwriter')
                info_message_parts.append(f"- {xlsx_path}")

            info_message = "Archivos generados correctamente en:\n\n" + "\n".join(info_message_parts)

            if self.generate_report.get() and self.cambios_log:
                reporte_df = pd.DataFrame(self.cambios_log)
                reporte_df = reporte_df[['NUM_DOC', 'CAMPO_MODIFICADO', 'VALOR_ANTERIOR', 'VALOR_NUEVO', 'FUENTE']]
                reporte_path = os.path.join(output_dir, f"REPORTE_DE_CAMBIOS_{base_filename}.xlsx")
                reporte_df.to_excel(reporte_path, index=False, engine='xlsxwriter')
                info_message += f"\n\n- Reporte de cambios:\n  {reporte_path}"

            self.progress.set(1.0)
            self.status_label.configure(text="¡Proceso completado con éxito! ✅")
            messagebox.showinfo("Éxito", info_message)

        except Exception as e:
            self.status_label.configure(text="Error durante el proceso. ❌")
            messagebox.showerror("Error",
                                 f"Ocurrió un error inesperado:\n\n{e}\n\nPor favor, revisa los archivos y los nombres de las columnas.")
        finally:
            self.progress.set(0)


if __name__ == "__main__":
    root = ctk.CTk()
    app = AppPAIUpdater(root)
    root.mainloop()
